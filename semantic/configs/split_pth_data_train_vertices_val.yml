
prop_type: vtx_
# prop_type: sampled_

# training: keep only chunks with atleast these many points
# n_points_threshold: 5000
n_points_threshold: 0
# and n unique labels (including ignore labels)
# n_labels_threshold: 5
n_labels_threshold: 0
# n instances threshold = number of unique instance IDs
# n_instances_threshold: 3
n_instances_threshold: 0

ignore_label: -100
# this frac of every instance should be within the chunk, if not, discard the instance
instance_frac_threshold: 0.8

# original scene list
orig_list_path: /mnt/hdd/scannetpp/splits/nvs_sem_val.txt
# original pth files
orig_pth_dir: /mnt/hdd/scannetpp/preprocessed_data_vertices

# output scene list
out_list_path: /mnt/hdd/scannetpp/split_preprocessed_data_vertices/splits/val.txt
# output pth dir
out_pth_dir: /mnt/hdd/scannetpp/split_preprocessed_data_vertices

# dimension of each chunk in XY
chunk_dims_xy: [5, 5]
# training: overlapping chunks
chunk_stride_xy: [5, 5]